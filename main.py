import cv2
import numpy as np
import os
from insightface.app import FaceAnalysis
from deepface import DeepFace
from openvino.runtime import Core

# ----------- 1. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª–µ–π ------------
face_app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])
face_app.prepare(ctx_id=0)

core = Core()
age_gender_model = core.read_model(model="models/intel/age-gender-recognition-retail-0013/FP32/age-gender-recognition-retail-0013.xml")
age_gender_compiled = core.compile_model(model=age_gender_model, device_name="CPU")
attr_model = core.read_model(model="models/intel/person-attributes-recognition-crossroad-0230/FP32/person-attributes-recognition-crossroad-0230.xml")
attr_compiled = core.compile_model(model=attr_model, device_name="CPU")
emotion_model = core.read_model(model="models/intel/emotions-recognition-retail-0003/FP32/emotions-recognition-retail-0003.xml")
emotion_compiled = core.compile_model(model=emotion_model, device_name="CPU")

def confident_label(score, label, threshold=0.75):
    if score is None:
        return "–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ"
    return label if score >= threshold else "–Ω–µ–≤–ø–µ–≤–Ω–µ–Ω–æ"

def fairface_predict(crop):
    return {"gender": None, "age": None, "race": None}
def deepfashion_predict(crop):
    return {"clothes_type": None, "clothes_color": None}
def beauty_score_predict(crop):
    return None
def hairnet_predict(crop):
    return {"hair_style": None, "hair_color": None}
def skin_status_predict(crop):
    return None
def jewellery_predict(crop):
    return None
def smile_predict(crop):
    return None
def makeup_predict(crop):
    return None
def height_weight_estimate(pose):
    return {"height": None, "weight": None}

# ----------- 2. –û–±—Ä–æ–±–∫–∞ –≤—ñ–¥–µ–æ ------------
video_path = "video.mp4"
output_frames_dir = "frames"
os.makedirs(output_frames_dir, exist_ok=True)

cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("–í—ñ–¥–µ–æ –Ω–µ –≤—ñ–¥–∫—Ä–∏—Ç–æ! –ü–µ—Ä–µ–≤—ñ—Ä –Ω–∞–∑–≤—É —Ç–∞ —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É.")
    exit()
frame_rate = cap.get(cv2.CAP_PROP_FPS)
interval_sec = 2
interval_frames = int(frame_rate * interval_sec) if frame_rate > 0 else 30
frame_num = 0
saved_num = 0

frames_info = []

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    if frame_num % interval_frames == 0:
        fname = f"frame_{saved_num:03d}.jpg"
        frame_path = os.path.join(output_frames_dir, fname)
        cv2.imwrite(frame_path, frame)
        faces = face_app.get(frame)
        faces_info = []
        for face in faces:
            box = face.bbox.astype(int)
            y1, y2 = max(box[1], 0), min(box[3], frame.shape[0])
            x1, x2 = max(box[0], 0), min(box[2], frame.shape[1])
            cropped_face = frame[y1:y2, x1:x2]
            if cropped_face is None or cropped_face.size == 0:
                continue

            sex = confident_label(getattr(face, "sex_score", None), "—á–æ–ª–æ–≤—ñ–∫" if face.sex == 1 else "–∂—ñ–Ω–∫–∞")
            age = int(face.age)
            glasses = confident_label(getattr(face, "glasses_score", None), "—î" if face.glasses else "–Ω–µ–º–∞—î")
            beard = confident_label(getattr(face, "beard_score", None), "—î" if face.beard else "–Ω–µ–º–∞—î")
            emotion = getattr(face, "emotion", "–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ")
            liveness = confident_label(getattr(face, 'liveness_score', 1.0), "–∂–∏–≤–∏–π")
            pose = getattr(face, "pose", "–Ω–µ–≤—ñ–¥–æ–º–æ")
            mask = "—î" if getattr(face, 'mask', False) else "–Ω–µ–º–∞—î"

            deep = DeepFace.analyze(cropped_face, actions=['age', 'gender', 'emotion', 'race'], enforce_detection=False)
            if isinstance(deep, list):
                deep_attr = deep[0] if len(deep) > 0 else {}
            else:
                deep_attr = deep if deep is not None else {}
            gender_deep = deep_attr.get("gender", "–Ω–µ–≤—ñ–¥–æ–º–æ")
            age_deep = deep_attr.get("age", "–Ω–µ–≤—ñ–¥–æ–º–æ")
            emotion_deep = deep_attr.get("dominant_emotion", "–Ω–µ–≤—ñ–¥–æ–º–æ")
            race_deep = deep_attr.get("dominant_race", "–Ω–µ–≤—ñ–¥–æ–º–æ")

            fairface_attr = fairface_predict(cropped_face)
            gender_fairface = fairface_attr.get("gender")
            age_fairface = fairface_attr.get("age")
            race_fairface = fairface_attr.get("race")

            resized_person = cv2.resize(frame, (80, 160))
            input_blob = np.expand_dims(resized_person.transpose(2, 0, 1), axis=0)
            attr_results = attr_compiled([input_blob])
            keys = ["—Å—Ç–∞—Ç—å (OpenVINO)", "—Å—É–º–∫–∞", "–∫–∞–ø–µ–ª—é—Ö", "–¥–æ–≤–≥—ñ —Ä—É–∫–∞–≤–∏", "–¥–æ–≤–≥—ñ —à—Ç–∞–Ω–∏", "–¥–æ–≤–≥–µ –≤–æ–ª–æ—Å—Å—è", "–∫—É—Ä—Ç–∫–∞/–ø—ñ–¥–∂–∞–∫", "—Å–æ–Ω—Ü–µ–∑–∞—Ö–∏—Å–Ω—ñ –æ–∫—É–ª—è—Ä–∏"]
            person_attr = {k: ("—î" if v > 0.75 else "–Ω–µ–º–∞—î") for k, v in zip(keys, attr_results[0][0])}

            if cropped_face is not None and cropped_face.size > 0:
                try:
                    age_gender_input = cv2.resize(cropped_face, (62, 62))
                    age_gender_input = np.expand_dims(age_gender_input.transpose(2, 0, 1), axis=0)
                    ag_results = age_gender_compiled([age_gender_input])
                    openvino_age = int(ag_results["age_conv3"][0][0][0][0] * 100)
                    male_score, female_score = ag_results["prob"][0]
                    openvino_gender = "—á–æ–ª–æ–≤—ñ–∫" if male_score > female_score else "–∂—ñ–Ω–∫–∞"
                except Exception as e:
                    openvino_age = None
                    openvino_gender = "–Ω–µ–≤—ñ–¥–æ–º–æ"
            else:
                openvino_age = None
                openvino_gender = "–Ω–µ–≤—ñ–¥–æ–º–æ"

            if cropped_face is not None and cropped_face.size > 0:
                try:
                    emotion_input = cv2.resize(cropped_face, (64, 64))
                    emotion_input = np.expand_dims(emotion_input.transpose(2, 0, 1), axis=0)
                    emotion_results = emotion_compiled([emotion_input])
                    emotions_list = ["neutral", "happy", "sad", "surprise", "anger"]
                    emotion_openvino = emotions_list[np.argmax(emotion_results[0][0])] if emotion_results[0][0].size == 5 else "–Ω–µ–≤—ñ–¥–æ–º–æ"
                except Exception as e:
                    emotion_openvino = "–Ω–µ–≤—ñ–¥–æ–º–æ"
            else:
                emotion_openvino = "–Ω–µ–≤—ñ–¥–æ–º–æ"

            deepfashion_attr = deepfashion_predict(frame)
            clothes_type = deepfashion_attr.get("clothes_type")
            clothes_color = deepfashion_attr.get("clothes_color")

            hair_attr = hairnet_predict(cropped_face)
            hair_style = hair_attr.get("hair_style")
            hair_color = hair_attr.get("hair_color")

            skin_status = skin_status_predict(cropped_face)
            beauty_score = beauty_score_predict(cropped_face)
            jewellery = jewellery_predict(cropped_face)
            smile = smile_predict(cropped_face)
            makeup = makeup_predict(cropped_face)
            height_weight = height_weight_estimate(pose)
            height_estimate = height_weight.get("height")
            weight_estimate = height_weight.get("weight")

            genders = [
                str(sex),
                str(gender_deep),
                str(person_attr.get("—Å—Ç–∞—Ç—å (OpenVINO)", "–Ω–µ–≤—ñ–¥–æ–º–æ")),
                str(openvino_gender),
                str(gender_fairface) if gender_fairface else "",
            ]
            gender_final = max(set(genders), key=genders.count)

            face_attrs = {
                "–°—Ç–∞—Ç—å (ensemble)": gender_final,
                "–°—Ç–∞—Ç—å (InsightFace)": sex,
                "–°—Ç–∞—Ç—å (DeepFace)": gender_deep,
                "–°—Ç–∞—Ç—å (FairFace)": gender_fairface,
                "–°—Ç–∞—Ç—å (OpenVINO)": person_attr["—Å—Ç–∞—Ç—å (OpenVINO)"],
                "–°—Ç–∞—Ç—å (OpenVINO-AG)": openvino_gender,
                "–í—ñ–∫ (InsightFace)": age,
                "–í—ñ–∫ (DeepFace)": age_deep,
                "–í—ñ–∫ (FairFace)": age_fairface,
                "–í—ñ–∫ (OpenVINO)": openvino_age,
                "–†–∞—Å–∞ (DeepFace)": race_deep,
                "–†–∞—Å–∞ (FairFace)": race_fairface,
                "–û–∫—É–ª—è—Ä–∏": glasses,
                "–°–æ–Ω—Ü–µ–∑–∞—Ö–∏—Å–Ω—ñ –æ–∫—É–ª—è—Ä–∏": person_attr.get("—Å–æ–Ω—Ü–µ–∑–∞—Ö–∏—Å–Ω—ñ –æ–∫—É–ª—è—Ä–∏"),
                "–ë–æ—Ä–æ–¥–∞": beard,
                "–ó–∞—á—ñ—Å–∫–∞": hair_style,
                "–ö–æ–ª—ñ—Ä –≤–æ–ª–æ—Å—Å—è": hair_color,
                "–ï–º–æ—Ü—ñ—è (InsightFace)": emotion,
                "–ï–º–æ—Ü—ñ—è (DeepFace)": emotion_deep,
                "–ï–º–æ—Ü—ñ—è (OpenVINO)": emotion_openvino,
                "–ñ–∏–≤—ñ—Å—Ç—å": liveness,
                "–ü–æ—Å–º—ñ—à–∫–∞": smile,
                "–ú–∞–∫—ñ—è–∂": makeup,
                "–°—Ç–∞–Ω —à–∫—ñ—Ä–∏": skin_status,
                "–ï—Å—Ç–µ—Ç–∏—á–Ω–∞ –æ—Ü—ñ–Ω–∫–∞": beauty_score,
                "–ü—Ä–∏–∫—Ä–∞—Å–∏": jewellery,
                "–¢–∏–ø –æ–¥—è–≥—É": clothes_type,
                "–ö–æ–ª—ñ—Ä –æ–¥—è–≥—É": clothes_color,
                "–û–¥—è–≥ —Ç–∞ –∞–∫—Å–µ—Å—É–∞—Ä–∏ (OpenVINO)": {k: v for k, v in person_attr.items() if k != "—Å—Ç–∞—Ç—å (OpenVINO)"},
                "–ü–æ–∑–∞ –≥–æ–ª–æ–≤–∏": pose,
                "–ú–∞—Å–∫–∞ –Ω–∞ –æ–±–ª–∏—á—á—ñ": mask,
                "–ó—Ä—ñ—Å—Ç (–æ—Ü—ñ–Ω–∫–∞)": height_estimate,
                "–í–∞–≥–∞ (–æ—Ü—ñ–Ω–∫–∞)": weight_estimate
            }
            faces_info.append(face_attrs)
        frames_info.append({
            "frame_name": fname,
            "faces": faces_info
        })
        saved_num += 1
    frame_num += 1
cap.release()

# ----------- 3. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Å—É—á–∞—Å–Ω–æ–≥–æ HTML-—Ä–µ–ø–æ—Ä—Ç—É –∑ –ø—Ä–æ–ø—É—Å–∫–æ–º –Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–∏—Ö –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ ------------

def render_face_attrs(face):
    emoji_map = {
        "–°—Ç–∞—Ç—å (ensemble)": "üë§",
        "–°—Ç–∞—Ç—å (InsightFace)": "üë§",
        "–°—Ç–∞—Ç—å (DeepFace)": "üë§",
        "–°—Ç–∞—Ç—å (FairFace)": "üë§",
        "–°—Ç–∞—Ç—å (OpenVINO)": "üë§",
        "–°—Ç–∞—Ç—å (OpenVINO-AG)": "üë§",
        "–í—ñ–∫ (InsightFace)": "üéÇ",
        "–í—ñ–∫ (DeepFace)": "üéÇ",
        "–í—ñ–∫ (FairFace)": "üéÇ",
        "–í—ñ–∫ (OpenVINO)": "üéÇ",
        "–†–∞—Å–∞ (DeepFace)": "üåé",
        "–†–∞—Å–∞ (FairFace)": "üåé",
        "–û–∫—É–ª—è—Ä–∏": "üëì",
        "–°–æ–Ω—Ü–µ–∑–∞—Ö–∏—Å–Ω—ñ –æ–∫—É–ª—è—Ä–∏": "üï∂Ô∏è",
        "–ë–æ—Ä–æ–¥–∞": "üßî",
        "–ó–∞—á—ñ—Å–∫–∞": "üíá",
        "–ö–æ–ª—ñ—Ä –≤–æ–ª–æ—Å—Å—è": "üé®",
        "–ï–º–æ—Ü—ñ—è (InsightFace)": "üòä",
        "–ï–º–æ—Ü—ñ—è (DeepFace)": "üòä",
        "–ï–º–æ—Ü—ñ—è (OpenVINO)": "üòä",
        "–ñ–∏–≤—ñ—Å—Ç—å": "üë§",
        "–ü–æ—Å–º—ñ—à–∫–∞": "üòÅ",
        "–ú–∞–∫—ñ—è–∂": "üíÑ",
        "–°—Ç–∞–Ω —à–∫—ñ—Ä–∏": "üß¥",
        "–ï—Å—Ç–µ—Ç–∏—á–Ω–∞ –æ—Ü—ñ–Ω–∫–∞": "üèÖ",
        "–ü—Ä–∏–∫—Ä–∞—Å–∏": "üíç",
        "–¢–∏–ø –æ–¥—è–≥—É": "üëï",
        "–ö–æ–ª—ñ—Ä –æ–¥—è–≥—É": "üé®",
        "–ü–æ–∑–∞ –≥–æ–ª–æ–≤–∏": "üß≠",
        "–ú–∞—Å–∫–∞ –Ω–∞ –æ–±–ª–∏—á—á—ñ": "üò∑",
        "–ó—Ä—ñ—Å—Ç (–æ—Ü—ñ–Ω–∫–∞)": "üìè",
        "–í–∞–≥–∞ (–æ—Ü—ñ–Ω–∫–∞)": "‚öñÔ∏è"
    }
    html = ""
    for key, value in face.items():
        # –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è '–û–¥—è–≥ —Ç–∞ –∞–∫—Å–µ—Å—É–∞—Ä–∏ (OpenVINO)'
        if key == "–û–¥—è–≥ —Ç–∞ –∞–∫—Å–µ—Å—É–∞—Ä–∏ (OpenVINO)":
            val_str = ", ".join([f"{k}: {v}" for k, v in value.items() if v not in [None, "–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ"]])
            if val_str:
                html += f'<li><span class="emoji">üëö</span>–û–¥—è–≥ —Ç–∞ –∞–∫—Å–µ—Å—É–∞—Ä–∏ (OpenVINO): {val_str}</li>\n'
        else:
            # –Ø–∫—â–æ value ‚Äî numpy –º–∞—Å–∏–≤ –∞–±–æ —ñ–Ω—à–∏–π –Ω–µ—Å—Ç—Ä–æ–∫–æ–≤–∏–π —Ç–∏–ø, –≤—ñ–¥–æ–±—Ä–∞–∂–∞—î–º–æ —Ç—ñ–ª—å–∫–∏, —è–∫—â–æ —Ü–µ —Å—Ç—Ä–æ–∫–∞ –∞–±–æ —á–∏—Å–ª–æ –π –Ω–µ "–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ"
            skip = False
            if isinstance(value, np.ndarray):
                skip = True
            elif value is None:
                skip = True
            elif isinstance(value, str) and value == "–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ":
                skip = True
            if not skip:
                emoji = emoji_map.get(key, "")
                html += f'<li><span class="emoji">{emoji}</span>{key}: {value}</li>\n'
    return html

html_head = """
<!DOCTYPE html>
<html lang="uk">
<head>
<meta charset="utf-8">
<title>–ê—Ç—Ä–∏–±—É—Ç–∏ –≤—ñ–¥–µ–æ</title>
<style>
body {
  background: #f4f6f9;
  font-family: 'Segoe UI', Arial, sans-serif;
  margin: 0;
  padding: 0;
}
h1 {
  text-align: center;
  color: #222;
  margin-top: 2rem;
  letter-spacing: 2px;
}
.frame-card {
  background: #fff;
  border-radius: 14px;
  box-shadow: 0 2px 16px rgba(0,0,0,0.06);
  padding: 2rem;
  margin: 2rem auto;
  max-width: 900px;
}
.frame-title {
  font-size: 1.3rem;
  color: #2255a4;
  font-weight: 600;
  margin-bottom: 1rem;
  letter-spacing: 1px;
}
.frame-img {
  display: block;
  margin: 0 auto 1.2rem auto;
  border-radius: 10px;
  box-shadow: 0 2px 12px rgba(40,60,120,0.11);
  max-width: 400px;
}
.faces-grid {
  display: flex;
  gap: 2rem;
  flex-wrap: wrap;
  justify-content: flex-start;
  margin-top: 1.2rem;
}
.face-card {
  background: #eef2fa;
  border-radius: 12px;
  box-shadow: 0 1px 6px rgba(30,60,120,0.09);
  padding: 1.3rem;
  min-width: 250px;
  flex: 1 1 250px;
  margin-bottom: 1rem;
}
.face-title {
  color: #2b4d8c;
  font-weight: 600;
  margin-bottom: .7rem;
  font-size: 1.1rem;
  letter-spacing: .5px;
}
.face-attrs {
  list-style: none;
  padding: 0;
  margin: 0;
}
.face-attrs li {
  margin-bottom: .6rem;
  font-size: 1rem;
  color: #333;
  display: flex;
  align-items: center;
}
.face-attrs li span.emoji {
  font-size: 1.2em;
  margin-right: .5em;
}
.no-face {
  color: #b00;
  font-weight: 500;
  margin: 1rem 0;
  letter-spacing: 1px;
}
@media (max-width: 600px) {
  .frame-card {padding: 1rem;}
  .faces-grid {gap: 1rem;}
  .face-card {min-width: 180px;}
}
</style>
</head>
<body>
<h1>–ö–∞–¥—Ä–∏ –≤—ñ–¥–µ–æ —ñ —ó—Ö –∞—Ç—Ä–∏–±—É—Ç–∏</h1>
"""

html_body = ""
for frame in frames_info:
    html_body += f'<div class="frame-card">\n'
    html_body += f'  <div class="frame-title">{frame["frame_name"]}</div>\n'
    html_body += f'  <img src="frames/{frame["frame_name"]}" class="frame-img" alt="–ö–∞–¥—Ä">\n'
    if frame["faces"]:
        html_body += f'  <div class="faces-grid">\n'
        for idx, face in enumerate(frame["faces"], 1):
            html_body += f'    <div class="face-card">\n'
            html_body += f'      <div class="face-title">–û–±–ª–∏—á—á—è {idx}</div>\n'
            html_body += f'      <ul class="face-attrs">\n'
            html_body += render_face_attrs(face)
            html_body += f'      </ul>\n'
            html_body += f'    </div>\n'
        html_body += f'  </div>\n'
    else:
        html_body += f'  <div class="no-face">–û–±–ª–∏—á—á—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ</div>\n'
    html_body += f'</div>\n'

html_tail = "</body></html>"

with open("video_report.html", "w", encoding="utf-8") as f:
    f.write(html_head + html_body + html_tail)

print("video_report.html –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ!")